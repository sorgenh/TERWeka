\documentclass{article}

\usepackage[francais]{babel}
\def\printlandscape{\special{landscape}}    % Works with dvips.
%\usepackage{pstricks,pst-node,pst-tree}
%\usepackage{amssymb}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} 
\usepackage{fancybox} % for shadow and Bitemize
\usepackage{alltt}
\usepackage{graphicx}
\usepackage{caption} 
\usepackage{textgreek}

%\usepackage{epsfig}
\usepackage{fullpage}
%\usepackage{fancyhdr}
%\usepackage{moreverb}
%\usepackage{xspace}
\usepackage[colorlinks,hyperindex,bookmarks,linkcolor=blue,citecolor=blue,urlcolor=blue]{hyperref}
\usepackage{array,multirow,makecell}
\setcellgapes{1pt}
\makegapedcells
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash }b{#1}}
\newcolumntype{L}[1]{>{\raggedright\arraybackslash }b{#1}}
\newcolumntype{C}[1]{>{\centering\arraybackslash }b{#1}}
\usepackage{wrapfig}
\usepackage{epsf}
\usepackage{framed}

\usepackage{fancyvrb}
\usepackage{xcolor}
\definecolor{Zgris}{rgb}{0.87,0.85,0.85}

\newsavebox{\BBbox}

\newenvironment{DDbox}[1]{
	\begin{lrbox}{\BBbox}\begin{minipage}{\linewidth}}
		{\end{minipage}\end{lrbox}\noindent\colorbox{Zgris}{\usebox{\BBbox}} \\
		[.5cm]}

\title{Rapport du TER GMIN401 :\\ \textbf{Intégration et optimisation d’algorithmes de classifications supervisées pour Weka}}

\author{Par : ALIJATE Mehdi - NEGROS Hadrien - TURKI Batoul}

\date{31 Janvier 2014}

         
\begin{document}

\maketitle
\tableofcontents

\begin{abstract}
	
Ce sujet vise à intégrer et à optimiser des algorithmes de classifications supervisées de documents dans la suite logiciel WEKA. Ces algorithmes sont issus de travaux de recherche menés récemment au sein du LIRMM.
\end{abstract}

\newpage 
%-----------------------------------------------------------
\section{Introduction}\label{sec:intro}
La classification de documents est le mécanisme consistant à classer automatiquement des ressources la classe prédéfinie lui correspondant le mieux.\\
Plusieurs formes de classification existent (par genre, par opinion, par thème...etc), et se font via des algorithmes de classifications spécifiques. Ceux-ci se basent sur des méthodes principalement numériques (probabilistes), avec des algorithmes utilisant les mathématiques ou basés sur la recherche d'information. \\
Ce TER vise justement à intégrer des algorithmes de classifications supervisées de documents dans la suite logiciel WEKA\footnote{\href{http://www.cs.waikato.ac.nz/~ml/weka/}{Weka est une suite populaire de logiciels d'apprentissage automatique. Écrite en Java, développée à l'université de Waikato, Nouvelle-Zélande. Weka est un Logiciel libre disponible sous la Licence publique générale GNU.}}, se basant sur un nouveau modèle de classification à partir d'un faible nombre de document, intégrant de nouvelles pondérations adaptées.\\
Tout d'abord, il faudra explorer l'API de WEKA, pour prendre en main du code source, la maniabilité des classes et explorer une méthode d'ajout d'un algorithme de classification. Ensuite, nous nous pencherons sur le développement des différentes classes en établissant une méthodologie concrétisant le travail mené au laboratoire du LIRMM, s'en suivra une phase d'intégration et de tests.



%-----------------------------------------------------------

\section{Exploration de WEKA}
Après la réunion du 24/01/14, nous avons établi un plan de travail pour bien mener et répartir les tâches de ce TER. Il a été décidé de le diviser en trois grandes parties. La première, qui est décrite ci-dessous consiste à explorer et prendre en main l'API de WEKA, afin de pouvoir y rajouter les algorithmes que l'on aura développé lors de la deuxième partie, et qui seront testés et intégrés lors de la troisième.
\subsection{L'API Weka/Sources avec Eclipse}
Pour explorer l'API, nous nous sommes aidés de l'IDE Eclipse, qui permet facilement parcourir les sources d'une librairie externe. Après avoir étudié l'arborescence des classes de l'API, nous avons pu cibler les différentes classes et méthodes qui nous intéressent, et étudié leurs fonctionnement. Nous nous sommes aidé de ce wiki \footnote{\href{http://weka.wikispaces.com/}{http://weka.wikispaces.com/}}.

\subsection{L'utilisation des classes}
Une fois familiarisés avec l'API Weka, on a creusé un peu plus du côté des classes qui pourraient nous être utiles pour ce TER. Il s'agit des certaines classes présentes dans le package{\scriptsize { \normalsize "weka.classifiers"}}. En effet, notre but étant d'intégrer des algorithmes de classification, il est utile de savoir comment tournent les algorithmes de classifications, leur paramétrage et l'architecture pour organiser les ressources pour ces derniers.\\
Quelques tests ont été menés notamment pour bayes naif multinomial, que nous avons fait tourné sur différentes données, et avec différentes options.
\subsection{Ajout d'un algorithme dans Weka}\label{sec:algoW}
Après avoir étudié en détail la classe \textit{NaiveBayesMultinomial}, nous avons remarqué que le calcul des pondérations (dans l'implémentation de Weka, seul la mesure intra-classe Tf est utilisée) se fait dans la méthode \textbf{buildClassifier}. Nous allons donc créer une sous classe de \textit{NaiveBayesMultinomial}, contenant une méthode surchargeant \textbf{buildClassifier} dans laquelle nous calculerons toutes les pondérations supplémentaires.\\
Une fois tout cela creusé et vu en détails, il faudra intégrer l'algorithme dans l'écosystème de Weka, c'est à dire, pour le rendre disponible dans l'Explorateur, expérimentateur, etc . 
Weka prend en charge les classes dérivées dans le package, ceci est géré par le \textit{GenericPropertiesCreator}. Il faudra donc dire à Weka où trouver notre nouveau classificateur et il s'occupera de l'afficher dans la \textit{GenericObjectEditor}.\\
Nous y reviendrons plus en détails lors de la troisième étape de notre TER : L'intégration des algorithmes dans WEKA.
%-----------------------------------------------------------
\section{Des nouvelles méthodes de classification}

\subsection{Pondérations intra-classes}
//TODO
\subsection{Pondérations inter-classes}
//TODO
\subsection{Algorithmes de classifications}
//TODO
%-----------------------------------------------------------



\section{Développement des différentes classes}\label{sec:classes}

\subsection{Méthodologie}
//TODO
\subsection{Extension de Naive Bayes Multinomial}
//TODO
\subsection{Class-Feature-Centroide}
//TODO
%-----------------------------------------------------------



\section{Intégration et tests}
\subsection{Intégration dans l'écosystème de Weka}
Une fois nos classes, et donc nos trois algorithmes implémenter en langage Java (Cf. Chapitre \ref{sec:classes} ) :
\begin{itemize}
\item  \texttt{NaiveBayesMultinomialTER.java} : construit le modèle de classification avec les quatre pondérations définies (le choix de la pondération se fait via les options).
\item  \texttt{NaiveBayesMultinomialTERab.java} : construit le modèle de classification avec les quatre pondérations définies en variant les valeurs de a : \textalpha \ et b : \textbeta \ (le choix des valeurs de \textalpha \ et \textbeta \ se fait via les options).
\item  \texttt{CFCTERab.java} : construit le modèle de classification Class-Feature-Centroide en variant les valeurs de a: \textalpha \ et b : \textbeta \ (le choix des valeurs de \textalpha \ et \textbeta \ se fait via les options).
\end{itemize}
Une fois nos trois .java prêts, l'intégration dans Weka est prise en charge via  \textit{GenericPropertiesCreator}. C'est là où on peut dire à Weka où trouver nos nouveaux classifieurs et il s'occupera de les afficher dans  \textit{GenericObjectEditor}, et donc dans l'interface graphique. La procédure détaillée est : \\
\textbf{\underline{Prérequis :}}

\begin{itemize}
\item ANT : logiciel créé par la fondation Apache qui vise à automatiser l'opération de construction d'un JAR.\footnote{\href{http://ant.apache.org/}{http://ant.apache.org/}}
\item JDK
\item Weka (version 3.6.10 dans notre cas)
\end{itemize}
\textbf{\underline{Préparation de Weka}}\\
À l'aide d'un gestionnaire d'archives, il faudra désarchiver weka-src.jar, qui se trouve dans le répértoire de Weka une fois ce dernier installer. Ceci vous donne accès aux différents répértoires et sources du logiciel.\\
\textit{NB :} Pour éviter toutes confusions ou conflits, il est préférable de créer un dossier \textit{temp} par exemple, et d'y mettre votre répértoire \textit{weka-src}.\\
\textbf{\underline{Ajout des nouveaux classifieurs dans Weka}}\\
À ce stade du processus d'ajout des algorithmes dans Weka, il faut modifier le fichier GenericObjectEditor.props (non le .java, se trouvant au même répértoire), qui se trouve dans \\
 \texttt{/temp/weka/weka-src/src/java/weka/gui/}, en y ajoutant les trois lignes suivantes : \\
 \texttt{weka.classifier.bayes.CFCTERab,\textbackslash}\\
 \texttt{weka.classifier.bayes.NaiveBayesMultinomialTER,\textbackslash}\\
 \texttt{weka.classifier.bayes.NaiveBayesMultinomialTERab,\textbackslash}\\
 et ce, en respectant l'ordre alphabétique défini dans le fichier, et surtout au bon endroit (dans la liste après le marquage suivant :  \texttt{\# Lists the Classifiers I want to choose from} ).\\
Ensuite, il suffit de placer les trois fichiers .java développés dans le répertoire :\\
 \texttt{/temp/weka/weka-src/src/java/weka/classifiers/bayes/}.\\
 \textbf{\underline{Reconstruction de Weka}}\\
 Comme son nom l'indique bien, cette dernière étape permet de reconstruire Weka avec ses nouvelles propriétés. Il suffit, après avoir installé ANT(voir prérequis ci-dessus), de se placer dans le répértoire \\
  \texttt{/temp/weka/weka-src/}, à l'aide d'un terminal, et lancer la commande suivante : \\
\texttt{ant exejar}\\
Celle-ci fera appel automatiquement au fichier \texttt{build.xml}, qui, comme expliqué dans la sous-section \ref{sec:algoW}, construira de nouveau Weka, et donnera en sortie dans le répertoire \texttt{/temp/weka/weka-src/dist/} un nouvel executable \texttt{weka.jar}, contenant les nouveaux algorithmes de classifications.
\subsection{Tests}
Afin de tester la pertinence de nos nouveaux algorithmes de classifications, nous avons créer 2 fichiers \texttt{.arff}, avec deux jeux de données aléatoires mais cohérents. 
\begin{itemize}
\item \texttt{\textbf{test3classes.arff}} : \textbf{150} instances et \textbf{41} attributs (une selection d'attributs a été faite dessus), avec \textbf{3} classes : Policier, Fantastique, Comédie.
\item \texttt{\textbf{test5classes.arff}} : \textbf{248} instances et \textbf{5082} attributs au complet (sans selection d'attributs), avec \textbf{5} classes : Thriller, Western, Guerre, Policier, Sciences.
\end{itemize}
Le but étant de classifié les films selon leur catégorie cinématographique .
Nos deux fichiers .arff ont subi de multiples tests avec nos trois algorithmes, avec différentes valeurs pour nos variables \textalpha \ et \textbeta, que ce soit pour le NaiveBayesMultinomialTERab ou le CFCTERab.\\
Les résultats des tests sont donnés dans la section ci-dessous.

\subsection{Résultats}
Les deux tableaux suivants montrent les résultats relevés suite aux expérimentations effectuées avec nos trois algorithmes sur nos deux fichiers de tests.

\begin{table*}[h]
\centering
    \begin{tabular}{|l|c|c|c|c||c|}
    \hline
    NBMultinomialTER/fichierTest  & $Nb^{Tf-Class}$ & $Nb^{Df-Class}$& $Nb^{Tf-Doc}$ & $Nb^{Df-Doc}$ & NBMultinomial \\ \hline
    test3classes.arff &   66\% & \textbf{67\%}   & 64\%  & 66\% & 66\%  \\ \hline
    test5classes.arff & 52\%  & \textbf{68\%} & 51\% & 50\% & 63\%  \\ \hline
    \end{tabular}
    \caption {Expérimentations avec les quatre pondérations et comparaison avec NBMultinomial}
 \label{NBTER}
\end{table*}
Le tableau \ref{NBTER} présente les résultats de classifications correctes atteintes avec distinctement les quatre pondérations $Nb^{Tf-Class}$, $Nb^{Df-Class}$, $Nb^{Tf-Doc}$ et $Nb^{Df-Doc}$ de notre algorithme  \texttt{NaiveBayesMultinomialTER}. Nous constatons que l'utilisation de la pondération $W^{Df-Class}$, pour nos deux jeux de données, donne des résultats supérieurs à ceux d'une classification avec NaïveBayesMultinomial.
\begin{table*}[h]
\centering
    \begin{tabular}{|l|c|c|c|c||c|}
\hline
 Algo/FichierTest & \textalpha & \textbeta & NBMTER\textalpha\textbeta & CFCTER\textalpha\textbeta & NBMultinomial \\
    \hline
    test3classes.arff &  \textalpha = 0.0 & \textbeta = 1.0& \textbf{67\%} & 68\% & 66\% \\
    \cline{2-5}
         ~ &  \textalpha = 0.6  & \textbeta = 0.6 & 66\% & \textbf{74\%} & ~\\
         \cline{2-5}
         ~ &  \textalpha = 0.7  & \textbeta = 0.3 & 66\% & \textbf{73\%} & ~\\
    \hline
     test5classes.arff & \textalpha = 0.0 & \textbeta = 1.0& \textbf{67\%} &\textbf{68\%} & 63\% \\
    \cline{2-5}
         ~ &  \textalpha = 0.6  & \textbeta = 0.6 & 65\% & \textbf{70\%} & ~\\
         \cline{2-5}
         ~ &  \textalpha = 0.7  & \textbeta = 0.3 & 58\% & 60\% & ~\\
    \hline
    \end{tabular}
    \caption {Expérimentations avec différentes valeurs de \textalpha  \ et \textbeta \  pour NBTER\textalpha\textbeta \ et CFCTER\textalpha\textbeta}
 \label{NBab}
\end{table*}
%-----------------------------------------------------------


\section{Discussion et Conclusion }
//TODO
%-----------------------------------------------------------

\section{Sources}
//TODO

%-----------------------------------------------------------

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% coding: utf-8
%%% End:
