\documentclass{article}

\usepackage[francais]{babel}
\def\printlandscape{\special{landscape}}    % Works with dvips.
%\usepackage{pstricks,pst-node,pst-tree}
%\usepackage{amssymb}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} 
\usepackage{fancybox} % for shadow and Bitemize
\usepackage{alltt}
\usepackage{graphicx}
\usepackage{caption} 
\usepackage{textgreek}

%\usepackage{epsfig}
\usepackage{fullpage}
%\usepackage{fancyhdr}
%\usepackage{moreverb}
%\usepackage{xspace}
\usepackage[colorlinks,hyperindex,bookmarks,linkcolor=blue,citecolor=blue,urlcolor=blue]{hyperref}
\usepackage{array,multirow,makecell}
\setcellgapes{1pt}
\makegapedcells
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash }b{#1}}
\newcolumntype{L}[1]{>{\raggedright\arraybackslash }b{#1}}
\newcolumntype{C}[1]{>{\centering\arraybackslash }b{#1}}
\usepackage{wrapfig}
\usepackage{epsf}
\usepackage{framed}

\usepackage{fancyvrb}
\usepackage{xcolor}
\definecolor{Zgris}{rgb}{0.87,0.85,0.85}

\newsavebox{\BBbox}

\newenvironment{DDbox}[1]{
	\begin{lrbox}{\BBbox}\begin{minipage}{\linewidth}}
		{\end{minipage}\end{lrbox}\noindent\colorbox{Zgris}{\usebox{\BBbox}} \\
		[.5cm]}

\title{Rapport du TER GMIN401 :\\ \textbf{Intégration et optimisation d’algorithmes de classifications supervisées pour Weka}}

\author{Par : ALIJATE Mehdi - NEGROS Hadrien - TURKI Batoul}

\date{31 Janvier 2014}

         
\begin{document}

\maketitle
\tableofcontents

\begin{abstract}
	
Ce sujet vise à intégrer et à optimiser des algorithmes de classifications supervisées de documents dans la suite logiciel WEKA. Ces algorithmes sont issus de travaux de recherche menés récemment au sein du LIRMM.
\end{abstract}

\newpage 
%-----------------------------------------------------------
\section{Introduction}\label{sec:intro}
La classification de documents est le mécanisme consistant à classer automatiquement des ressources la classe prédéfinie lui correspondant le mieux.\\
Plusieurs formes de classification existent (par genre, par opinion, par thème...etc), et se font via des algorithmes de classifications spécifiques. Ceux-ci se basent sur des méthodes principalement numériques (probabilistes), avec des algorithmes utilisant les mathématiques ou basés sur la recherche d'information. \\
Ce TER vise justement à intégrer des algorithmes de classifications supervisées de documents dans la suite logiciel WEKA\footnote{\href{http://www.cs.waikato.ac.nz/~ml/weka/}{Weka est une suite populaire de logiciels d'apprentissage automatique. Écrite en Java, développée à l'université de Waikato, Nouvelle-Zélande. Weka est un Logiciel libre disponible sous la Licence publique générale GNU.}}, se basant sur un nouveau modèle de classification à partir d'un faible nombre de document, intégrant de nouvelles pondérations adaptées.\\
Tout d'abord, il faudra explorer l'API de WEKA, pour prendre en main du code source, la maniabilité des classes et explorer une méthode d'ajout d'un algorithme de classification. Ensuite, nous nous pencherons sur le développement des différentes classes en établissant une méthodologie concrétisant le travail mené au laboratoire du LIRMM, s'en suivra une phase d'intégration et de tests.


%-----------------------------------------------------------

\section{Exploration de WEKA}
Après la réunion du 24/01/14, nous avons établi un plan de travail pour bien mener et répartir les tâches de ce TER. Il a été décidé de le diviser en trois grandes parties. La première, qui est décrite ci-dessous consiste à explorer et prendre en main l'API de WEKA, afin de pouvoir y rajouter les algorithmes que l'on aura développé lors de la deuxième partie, et qui seront testés et intégrés lors de la troisième.
\subsection{L'API Weka/Sources avec Eclipse}
Pour explorer l'API, nous nous sommes aidés de l'IDE Eclipse, qui permet facilement parcourir les sources d'une librairie externe. Après avoir étudié l'arborescence des classes de l'API, nous avons pu cibler les différentes classes et méthodes qui nous intéressent, et étudié leurs fonctionnement. Nous nous sommes aidé de ce wiki \footnote{\href{http://weka.wikispaces.com/}{http://weka.wikispaces.com/}}.

\subsection{L'utilisation des classes}
Une fois familiarisés avec l'API Weka, on a creusé un peu plus du côté des classes qui pourraient nous être utiles pour ce TER. Il s'agit des certaines classes présentes dans le package{\scriptsize { \normalsize "weka.classifiers"}}. En effet, notre but étant d'intégrer des algorithmes de classification, il est utile de savoir comment tournent les algorithmes de classifications, leur paramétrage et l'architecture pour organiser les ressources pour ces derniers.\\
Quelques tests ont été menés notamment pour bayes naif multinomial, que nous avons fait tourné sur différentes données, et avec différentes options.
\subsection{Ajout d'un algorithme dans Weka}\label{sec:algoW}
Après avoir étudié en détail la classe \textit{NaiveBayesMultinomial}, nous avons remarqué que le calcul des pondérations (dans l'implémentation de Weka, seul la mesure intra-classe Tf est utilisée) se fait dans la méthode \textbf{buildClassifier}. Nous allons donc créer une sous classe de \textit{NaiveBayesMultinomial}, contenant une méthode surchargeant \textbf{buildClassifier} dans laquelle nous calculerons toutes les pondérations supplémentaires.\\
Une fois tout cela creusé et vu en détails, il faudra intégrer l'algorithme dans l'écosystème de Weka, c'est à dire, pour le rendre disponible dans l'Explorateur, expérimentateur, etc . 
Weka prend en charge les classes dérivées dans le package, ceci est géré par le \textit{GenericPropertiesCreator}. Il faudra donc dire à Weka où trouver notre nouveau classificateur et il s'occupera de l'afficher dans la \textit{GenericObjectEditor}.\\
Nous y reviendrons plus en détails lors de la troisième étape de notre TER : L'intégration des algorithmes dans WEKA.
%-----------------------------------------------------------
\section{De nouvelles méthodes de classification}
Dans cette partie, nous allons vous présenter les différentes pondérations que nous allons utiliser pour construire nos classifieurs.
Nous allons d'abord définir les mesures intra-classe inspirées du TF-IDF, puis les mesures inter-classe développées au \textit{LIRMM}.
Ces mesures vont nous permettre de définir si un terme (un élément d'un document) est plus ou moins représentatif de la classe.\\Toutes ces mesures ont étés définies dans l'article \textit{De nouvelles pondérations adaptées à la classification de petits volumes de données textuelles. }\cite{RNTIB}.
\subsection{Pondérations intra-classe}
Les pondérations que nous définissons ci-dessous sont dites \textbf{intra-classe} car les différentes valeurs que nous utilisons pour les
calculer sont dépendante d'une classe.
\subsubsection*{intra-classe document}
Cette mesure dépend du nombre de documents contenant le terme dans la classe.
  \[ inner\mbox{-}weight_{ij}^{Df} = \frac{DF_{ti}^j}{|d_{j}|}\]
  
      Avec:
  \begin{itemize}
  	\item $DF_{ti}^j$: Nombre de documents contenant le terme $t_i$ dans la classe $C_j$	
  	\item $|d_{j}|$: Nombre de documents dans $C_j$	
    \end{itemize}
\subsubsection*{intra-classe terme}
Cette mesure dépend du nombre d'occurrences du terme dans la classe.
\[   inner\mbox{-}weight_{ij}^{Tf} = \frac{TF_{ti}^j}{|n_{j}|}\]
  Avec:
\begin{itemize}
	\item $TF_{ti}^j$: Nombre d'occurrences du terme $t_i$ dans la classe $C_j$	
	\item $|n_{j}|$: Nombre de termes total dans la classe $C_j$	
  \end{itemize}
\subsection{Pondérations inter-classe}
Les pondérations inter-classes en revanche utilisent des valeurs calculées à partir de l'ensemble du corpus (depuis les classes extérieures à celle qui nous intéresse).
\subsubsection*{inter-classe terme}
Cette mesure dépend du nombre de classes contenant le terme.
\[inter\mbox{-}weight_{ij}^{class} = log_2 \frac{|C|}{C_{ti}}\]
Avec:
\begin{itemize}
	\item $|C|$: Nombre de classes			
	\item $C_{ti}$: Nombre de classes contenant le terme $t_i$
  \end{itemize}
\subsubsection*{inter-classe document}
Cette mesure dépend du nombre de documents extérieurs à la classe contenant le terme.
\[ inter\mbox{-}weight_{ij}^{doc} = log_2 \frac{|d \notin{C_j}|+1}{|d:t_i \notin{C_j}|+1}= log_2 \frac{|d|-|d \in{C_j}|+1}{|d:t_i|-|d:t_i \in{C_j}|+1}\]
 Avec:
\begin{itemize}
	\item $|d \notin  {C_j}|$: Nombre de documents n'appartenant pas à la classe $C_j$
	\item $|d:t_i \notin {C_j}|$: Nombre de documents n'appartenant pas à la classe $C_j$ qui contient $t_i$ 
	\item $|d|$: Nombre de documents dans l'ensemble des classes
	\item $|d \in  {C_j}|$: Nombre de documents de la classe $C_j$
	\item $|d:t_i|$: Nombre de documents dans l'ensemble des classes contenant le terme $t_i$ 
	\item $|d:t_i \in {C_j}|$: Nombre de documents de la classe $C_j$ qui contient $t_i$ 
	\item En ajoutant 1, permet de prévenir le cas où $t_i$ est uniquement utilisé dans $C_j$ (quand $|d:t_i \notin{C_j}|={|d:t_i|-|d:t_i \in{C_j}|} = 0$)
  \end{itemize}
\subsection{Algorithmes de classifications}
Un algorithme de classification permet de calculer la probabilité de l'appartenance d'un document aux différentes classes du corpus, et donc de l'affecter à la plus probable. Nous allons implémenter un classifieur \textit{Naive Bayes} et \textit{Class-Feature-Centroid}\cite{RNTIB} en utilisant les mesures définies plus haut. Pour calculer la probabilité $w_{ij}$ d'un terme $i$ dans une classe $j$, nous allons combiner les différentes pondérations de 4 façons:
\begin{itemize}
\item $w_{ij}^{Tf-Class}$=$inner$-$weight_{ij}^{Tf}$ $\times$ $inter$-$weight_{ij}^{class}$
%=$ \frac{TF_{ti}^j}{|n_{j}|}$ x $log_2 \frac{|C|}{CF_{ti}}$
\item $w_{ij}^{Df-Class}$=$inner$-$weight_{ij}^{Df}$ $\times$ $inter$-$weight_{ij}^{class}$
%=$\frac{DF_{ti}^j}{|d_{j}|}$ x $log_2 \frac{|C|}{CF_{ti}}$
\item $w_{ij}^{Tf-Doc}$=$inner$-$weight_{ij}^{Tf}$ $\times$ $inter$-$weight_{ij}^{doc}$
%=$ \frac{TF_{ti}^j}{|n_{j}|}$ x $log_2 \frac{|d|-|d \in{C_j}|+1}{|d:t_i|-|d:t_i \in{C_j}|+1}$
\item $w_{ij}^{Df-Doc}$=$inner$-$weight_{ij}^{Df}$ $\times$ $inter$-$weight_{ij}^{doc}$
%=$\frac{DF_{ti}^j}{|d_{j}|}$ x $log_2 \frac{|d|-|d \in{C_j}|+1}{|d:t_i|-|d:t_i \in{C_j}|+1}$
\end{itemize}
Nous allons aussi mettre en place une combinaison de ces mesures dépendante de deux paramètres $\alpha$ et $\beta$:
\[ w_{ij}^{ \alpha \beta}=(\alpha \times innerweight_{ij}^{Tf} + (1-\alpha)\times innerweight_{ij}^{Df} )\times(\beta \times interweight_{ij}^{class} + (1-\beta) \times interweight_{ij}^{doc} )\]
On remarque qu'en faisant varier $\alpha$ et $\beta$, on peut retrouver les quatre premières formules.
%-----------------------------------------------------------



\section{Développement des différentes classes}\label{sec:classes}

\subsection{Méthodologie}
//TODO
\subsection{Extension de Naive Bayes Multinomial}
//TODO
\subsection{Class-Feature-Centroide}
//TODO
%-----------------------------------------------------------



\section{Intégration et tests}\label{Res}
\subsection{Intégration dans l'écosystème de Weka}
Une fois nos classes, et donc nos trois algorithmes implémenter en langage Java (Cf. Chapitre \ref{sec:classes} ) :
\begin{itemize}
\item  \texttt{NaiveBayesMultinomialTER.java} : construit le modèle de classification avec les quatre pondérations définies (le choix de la pondération se fait via les options).
\item  \texttt{NaiveBayesMultinomialTERab.java} : construit le modèle de classification avec les quatre pondérations définies en variant les valeurs de a : \textalpha \ et b : \textbeta \ (le choix des valeurs de \textalpha \ et \textbeta \ se fait via les options).
\item  \texttt{CFCTERab.java} : construit le modèle de classification Class-Feature-Centroide en variant les valeurs de a: \textalpha \ et b : \textbeta \ (le choix des valeurs de \textalpha \ et \textbeta \ se fait via les options).
\end{itemize}
Une fois nos trois .java prêts, l'intégration dans Weka est prise en charge via  \textit{GenericPropertiesCreator}. C'est là où on peut dire à Weka où trouver nos nouveaux classifieurs et il s'occupera de les afficher dans  \textit{GenericObjectEditor}, et donc dans l'interface graphique. La procédure détaillée est : \\
\textbf{\underline{Prérequis :}}

\begin{itemize}
\item ANT : logiciel créé par la fondation Apache qui vise à automatiser l'opération de construction d'un JAR.\footnote{\href{http://ant.apache.org/}{http://ant.apache.org/}}
\item JDK
\item Weka (version 3.6.10 dans notre cas)
\end{itemize}
\textbf{\underline{Préparation de Weka}}\\
À l'aide d'un gestionnaire d'archives, il faudra désarchiver weka-src.jar, qui se trouve dans le répértoire de Weka une fois ce dernier installer. Ceci vous donne accès aux différents répértoires et sources du logiciel.\\
\textit{NB :} Pour éviter toutes confusions ou conflits, il est préférable de créer un dossier \textit{temp} par exemple, et d'y mettre votre répértoire \textit{weka-src}.\\
\textbf{\underline{Ajout des nouveaux classifieurs dans Weka}}\\
À ce stade du processus d'ajout des algorithmes dans Weka, il faut modifier le fichier GenericObjectEditor.props (non le .java, se trouvant au même répértoire), qui se trouve dans \\
 \texttt{/temp/weka/weka-src/src/java/weka/gui/}, en y ajoutant les trois lignes suivantes : \\
 \texttt{weka.classifier.bayes.CFCTERab,\textbackslash}\\
 \texttt{weka.classifier.bayes.NaiveBayesMultinomialTER,\textbackslash}\\
 \texttt{weka.classifier.bayes.NaiveBayesMultinomialTERab,\textbackslash}\\
 et ce, en respectant l'ordre alphabétique défini dans le fichier, et surtout au bon endroit (dans la liste après le marquage suivant :  \texttt{\# Lists the Classifiers I want to choose from} ).\\
Ensuite, il suffit de placer les trois fichiers .java développés dans le répertoire :\\
 \texttt{/temp/weka/weka-src/src/java/weka/classifiers/bayes/}.\\
 \textbf{\underline{Reconstruction de Weka}}\\
 Comme son nom l'indique bien, cette dernière étape permet de reconstruire Weka avec ses nouvelles propriétés. Il suffit, après avoir installé ANT(voir prérequis ci-dessus), de se placer dans le répértoire \\
  \texttt{/temp/weka/weka-src/}, à l'aide d'un terminal, et lancer la commande suivante : \\
\texttt{ant exejar}\\
Celle-ci fera appel automatiquement au fichier \texttt{build.xml}, qui, comme expliqué dans la sous-section \ref{sec:algoW}, construira de nouveau Weka, et donnera en sortie dans le répertoire \texttt{/temp/weka/weka-src/dist/} un nouvel executable \texttt{weka.jar}, contenant les nouveaux algorithmes de classifications.
\subsection{Tests}
Afin de tester la pertinence de nos nouveaux algorithmes de classifications, nous avons créer 2 fichiers \texttt{.arff}, avec deux jeux de données aléatoires mais cohérents. 
\begin{itemize}
\item \texttt{\textbf{test3classes.arff}} : \textbf{150} instances et \textbf{41} attributs (une selection d'attributs a été faite dessus), avec \textbf{3} classes : Policier, Fantastique, Comédie.
\item \texttt{\textbf{test5classes.arff}} : \textbf{248} instances et \textbf{5082} attributs au complet (sans selection d'attributs), avec \textbf{5} classes : Thriller, Western, Guerre, Policier, Sciences.
\end{itemize}
Le but étant de classifié les films selon leur catégorie cinématographique .
Nos deux fichiers .arff ont subi de multiples tests avec nos trois algorithmes, avec différentes valeurs pour nos variables \textalpha \ et \textbeta, que ce soit pour le NaiveBayesMultinomialTERab ou le CFCTERab.\\
Les résultats des tests sont donnés dans la section ci-dessous.

\subsection{Résultats}
Les deux tableaux suivants montrent les résultats relevés suite aux expérimentations effectuées avec nos trois algorithmes sur nos deux fichiers de tests.

\begin{table*}[h]
\centering
    \begin{tabular}{|l|c|c|c|c||c|}
    \hline
    NBMultinomialTER/fichierTest  & $Nb^{Tf-Class}$ & $Nb^{Df-Class}$& $Nb^{Tf-Doc}$ & $Nb^{Df-Doc}$ & NBMultinomial \\ \hline
    test3classes.arff &   66\% & \textbf{67\%}   & 64\%  & 66\% & 66\%  \\ \hline
    test5classes.arff & 52\%  & \textbf{68\%} & 51\% & 50\% & 63\%  \\ \hline
    \end{tabular}
    \caption {Expérimentations avec les quatre pondérations et comparaison avec NBMultinomial}
 \label{NBTER}
\end{table*}
\subparagraph*{•}
Le tableau \ref{NBTER} présente les résultats de classifications correctes atteintes avec distinctement les quatre pondérations $Nb^{Tf-Class}$, $Nb^{Df-Class}$, $Nb^{Tf-Doc}$ et $Nb^{Df-Doc}$ de notre algorithme  \texttt{NaiveBayesMultinomialTER}. Nous constatons que l'utilisation de la pondération $W^{Df-Class}$, pour nos deux jeux de données, donne des résultats supérieurs à ceux d'une classification avec  \texttt{NaiveBayesMultinomial}.
\begin{table*}[h]
\centering
    \begin{tabular}{|l|c|c|c|c||c|}
\hline
 Algo/FichierTest & \textalpha & \textbeta & NBMTER\textalpha\textbeta & CFCTER\textalpha\textbeta & NBMultinomial \\
    \hline
    test3classes.arff &  \textalpha = 0.0 & \textbeta = 1.0& \textbf{67\%} & 68\% & 66\% \\
    \cline{2-5}
         ~ &  \textalpha = 0.6  & \textbeta = 0.6 & 66\% & \textbf{74\%} & ~\\
         \cline{2-5}
         ~ &  \textalpha = 0.7  & \textbeta = 0.3 & 66\% & 73\% & ~\\
    \hline
     test5classes.arff & \textalpha = 0.0 & \textbeta = 1.0& \textbf{67\%} &68\% & 63\% \\
    \cline{2-5}
         ~ &  \textalpha = 0.6  & \textbeta = 0.6 & 65\% & \textbf{70\%} & ~\\
         \cline{2-5}
         ~ &  \textalpha = 0.7  & \textbeta = 0.3 & 58\% & 60\% & ~\\
    \hline
    \end{tabular}
    \caption {Expérimentations avec différentes valeurs de \textalpha  \ et \textbeta \  pour NBTER\textalpha\textbeta \ et CFCTER\textalpha\textbeta }
 \label{NBab}
\end{table*}
\subparagraph*{•}
Le tableau \ref{NBab} présente les résultats de classifications correctes atteintes avec nos deux algorithmes \texttt{NaiveBayesMultinomialTERab} et \texttt{CFCTERab}, en variant les valeurs de \textalpha  \ et \textbeta . Nous constatons que dans tous les cas où \textalpha $ \leq$ \textbeta , on est toujours supérieurs à  \texttt{NaiveBayesMultinomial}.   Parcontre, seul notre corpus réduit \texttt{test3classes.arff} donne des résultats $\geq$ à ceux de \texttt{NaiveBayesMultinomial} quand \textalpha \ > \textbeta .\\
Nous constatons aussi que \texttt{CFCTER\textalpha\textbeta} présente une meilleure classification que \texttt{NaiveBayesMultinomialTER\textalpha\textbeta}.
%-----------------------------------------------------------


\section{Discussion et Conclusion }
Dans ce TER, nous avons produit et intégré des bibliothèques Java, implémentant des nouvelles méthodes pertinentes et validées via des prototypes au sein du laboratoire LIRMM. Ces nouvelles méthodes de classifications sont maintenant intégrer dans l’environnement Weka.
Elles peuvent être utilisées aussi bien via l'interface graphique qu'en ligne de commande. Ces nouvelles mesures sont particulièrement adaptées aux faibles volumes de données, et, comme vu au chapitre \ref{Res}, ces mesures ont été tésté dans un cadre supervisé notamment via Naive Bayes (Multinomial) et une approche basée sur les centroides (CFC). \\
Les expérimentations menées aussi sur nos deux corpus de 3 et 5 classes ont permis de montrer que celles-ci ont généralement un meilleur comportement que l'approche existante de Naive Bayes Multinomial.\\
Les différents objectifs de ce TER, qui sont :\\
• Prise en main de Weka \\
• Développement des différentes bibliothèques en java \\
• L'intégration dans l’écosystème Weka \\
ont été atteint, les difficultés principales rencontrées étant de bien comprendre à la fois l'architecture interne et le fonctionnement de WEKA, ainsi que l'intuition qui porte les nouvelles mesures, ont axé et constitué la ligne directrice de notre travail, où nous avons mené une étude bibliographique sur l'article scientifique présentant la nouvelle méthodologie \cite{RNTIB}, ainsi qu'un parcours prolixe de la documentation de WEKA(cf. Wiki de Weka \ref{weka}).
%-----------------------------------------------------------

\newpage
\section{Sources}
\begin{itemize}
\item Wiki de Weka\label{weka}  : \href{http://weka.wikispaces.com/Writing+your+own+Classifier}{http://weka.wikispaces.com/Writing+your+own+Classifier}
 \\
\item Naive Bayes  : \href{$http://scikit-learn.org/stable/modules/naive_bayes.html$}{http://scikit-learn.org/stable/modules/naive\_bayes.html}


\end{itemize}

%-----------------------------------------------------------
\bibliographystyle{plain}
\bibliography{biblio}
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% coding: utf-8
%%% End:
